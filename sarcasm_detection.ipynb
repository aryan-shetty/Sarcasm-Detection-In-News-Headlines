{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the first dataset\n",
        "df1 = pd.read_json('Sarcasm_Headlines_Dataset.json', lines=True)\n",
        "\n",
        "# Load the second dataset\n",
        "df2 = pd.read_json('Sarcasm_Headlines_Dataset_v2.json', lines=True)\n",
        "\n",
        "# Concatenate both datasets into a single dataframe\n",
        "df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "# Calculate the total number of headlines\n",
        "total_headlines = len(df)\n",
        "\n",
        "# Calculate the percentage of sarcastic and non-sarcastic headlines\n",
        "num_sarcastic = df['is_sarcastic'].sum()\n",
        "num_non_sarcastic = total_headlines - num_sarcastic\n",
        "percentage_sarcastic = (num_sarcastic / total_headlines) * 100\n",
        "percentage_non_sarcastic = (num_non_sarcastic / total_headlines) * 100\n",
        "\n",
        "# Calculate the average headline length\n",
        "df['headline_length'] = df['headline'].apply(lambda x: len(x.split()))\n",
        "average_headline_length = df['headline_length'].mean()\n",
        "\n",
        "# Find the minimum and maximum headline lengths\n",
        "min_headline_length = df['headline_length'].min()\n",
        "max_headline_length = df['headline_length'].max()\n",
        "\n",
        "# Print the results\n",
        "print(\"Total number of headlines:\", total_headlines)\n",
        "print(\"Percentage of sarcastic headlines:\", percentage_sarcastic, \"%\")\n",
        "print(\"Percentage of non-sarcastic headlines:\", percentage_non_sarcastic, \"%\")\n",
        "print(\"Average headline length:\", average_headline_length, \"words\")\n",
        "print(\"Minimum headline length:\", min_headline_length, \"words\")\n",
        "print(\"Maximum headline length:\", max_headline_length, \"words\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ1lTYfiAu9A",
        "outputId": "5a6cbf43-5493-4dba-b044-8709967f9f20"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of headlines: 55328\n",
            "Percentage of sarcastic headlines: 45.83212839791787 %\n",
            "Percentage of non-sarcastic headlines: 54.16787160208213 %\n",
            "Average headline length: 9.951417004048583 words\n",
            "Minimum headline length: 2 words\n",
            "Maximum headline length: 151 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Load the datasets and combine them\n",
        "data_v1 = pd.read_json(\"Sarcasm_Headlines_Dataset.json\", lines=True)\n",
        "data_v2 = pd.read_json(\"Sarcasm_Headlines_Dataset_v2.json\", lines=True)\n",
        "data = pd.concat([data_v1, data_v2])\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X = data['headline']\n",
        "y = data['is_sarcastic']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Bag-of-Words representation of the headlines\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_bow = vectorizer.fit_transform(X_train)\n",
        "X_test_bow = vectorizer.transform(X_test)\n",
        "\n",
        "# Train the Multinomial Naive Bayes classifier\n",
        "clf = MultinomialNB(alpha=1.0)\n",
        "clf.fit(X_train_bow, y_train)\n",
        "\n",
        "# Make predictions on the test set with adjusted threshold\n",
        "threshold = 0.5\n",
        "y_pred_probs = clf.predict_proba(X_test_bow)\n",
        "y_pred_adjusted = (y_pred_probs[:, 1] > threshold).astype(int)\n",
        "\n",
        "# Evaluate the model with the adjusted threshold\n",
        "accuracy = accuracy_score(y_test, y_pred_adjusted)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "report = classification_report(y_test, y_pred_adjusted)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_adjusted)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5qSul6Pv9Kq",
        "outputId": "6bc36a51-720c-4e3c-80fe-accd1a72066a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8970721127778782\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90      5878\n",
            "           1       0.90      0.88      0.89      5188\n",
            "\n",
            "    accuracy                           0.90     11066\n",
            "   macro avg       0.90      0.90      0.90     11066\n",
            "weighted avg       0.90      0.90      0.90     11066\n",
            "\n",
            "Confusion Matrix:\n",
            " [[5374  504]\n",
            " [ 635 4553]]\n"
          ]
        }
      ]
    }
  ]
}